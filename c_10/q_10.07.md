# 「世界で闘うプログラミング力を鍛える150問」問題10.7

## 問題

シンプルなサーチエンジン用のウェブサーバーをイメージしてください。
このシステムは `processSearch(string query)` の形で検索クエリを受け付け、
結果を返すのに100台のマシンを使用します。
どのマシンが要求を受け付けているかはランダムに選ばれるので、
同じリクエストに対して常に同じマシンが応答するとは限りません。
また、 `processSearch` は高負荷なメソッドです。
このとき、最近のクエリに対するキャッシュのシステムを設計してください。
特に、変更されるデータに対するキャッシュの更新の仕方については必ず説明してください。

## 回答

曖昧な部分が多いので、最初に仮定を追加する。

* マシン毎に単独で `processSearch` に結果を返せるか否かが異なる。
  つまり、検索対象のデータをマシンごとにバラバラに持っている。
* 必要に応じて `processSearch` を呼び出す以外の全てのクエリ処理は、
  最初に呼び出されたマシンで発生する。
* キャッシュしたいクエリの数は大きい (百万単位)。
* マシン間の呼び出しは比較的速い。
  (が、キャッシュに比べれば非常に遅い)
* クエリによる結果は
  50文字のタイトルと200文字の概要を合わせたURIのリストとして整理される。
* 最も人気のあるクエリは、常にキャッシュに含まれているほど非常に人気がある。

言うまでもなく、他の仮定を考えてもよい。

また、システム要件として次の2つを考える。

* キー (クエリ) による効率の良い検索。
* クエリに対する結果が変わる場合、キャッシュを更新する。
* 新しいデータと置き換えるために (古い) データの生存期限を設定する。

これらを考慮して回答を考える。

### 単一マシンのキャッシュを設計する

最初に条件を簡単にして考えるため、単一マシンのみを考える。

* データはクエリの結果を保持する。
* クエリからデータを見つけるのにハッシュ・テーブル (C++11) を使う。
* 捨てるデータの順序を双方向リストによるキューで管理する。
  * 使われたデータはキューの末尾に移動する。
  * データ更新時もキューの末尾に移動する。
  * ずっと使われなかったデータがキューからあふれるときに削除される。

```
class Response
{
public:
	void* result_;			// 検索結果
	Response* previous_;	// 双方向リストにすることで、
	Response* next_;		// 新しい順のデータのリストが作成できる。
};

class Cache
{
private:
	unordered_map<std::string, Response*> table_;	// クエリとその検索結果
	Response* head_;	// リストの先頭ノード
	Response* tail_;	// リストの末尾ノード
	Response* buffer_;	// 削除されたノードの退避場所
	const size_t N_;	// リストの最大長

	void add_node(const std::string& query, Response* node) { ... }		// テーブルとリストにノードを追加
	void remove_node(const std::string& query) { ... }	// テーブルとリストからノードを削除
	void move_head(Response* node) { ... }		// ノードをリストの先頭に移動
	Response* new_node() { ... }				// 未使用ノードを確保

public:
	Cache(size_t n) : N_(n) { ... }
	virtual ~Cache() { ... }

	const void*
	getResult(const std::string& query)
		{
			Response* node;

			if (table_.find(query) != table_.end()) {
				node = *(table_.find(query));
				move_head(node);
			}
			else {
				node = new_node();
				node->result_ = processSearch(query);
				add_node(query, node);
				while (N_ < table_.size()) remove_node(tail_);
			}

			return node->result_;
		}

	void
	addResult(const std::string& query,
			  void* result)
		{
			Response* node;

			if (table_.find(query) != table_.end()) {
				node = *(table_.find(query));
				node->result_ = result;
				move_head(node);
			}
			else {
				node = new_node();
				node->result_ = result;
				add_node(query, node);
				while (N_ < table_.size()) remove_node(tail_);
			}
		}
};
```

### 複数のマシンに拡張する

1台のマシン上での設計が出来上がったので、
「どのマシンが要求を受け付けているかはランダムに選ばれる」という条件に注意しながら、
その拡張として複数台のマシンでどうするかを考える。

#### 選択1: 各マシンに独自のキャッシュを持つ

マシン間のやり取りを発生させず、各マシンがマシン内でのみキャッシュを利用する。

マシン間のやり取りが発生しないことから、単純であり比較的高速。
ただし、 `processSearch` の発生頻度を低減させるという目的においては、
少し非効率である。

#### 選択2: 各マシンにキャッシュのコピーを持たせる

あるマシンでキャッシュに項目が追加された場合、
そのコピーを他のマシン全てに送信して共有する。

マシン間でキャッシュのコピーを利用することから、
`processSearch` の発生頻度を大幅に低減させることができる。
もちろん、全てのマシンにコピーを送る負荷とのトレード・オフ。
また、完全に同じ内容のキャッシュを全てのマシンで持つことから、
冗長な部分が多くなる。

#### 選択3: 各マシンにキャッシュの一部分を持たせる

各マシンで重複がないようにキャッシュを持たせる。
例えば `i = hash(query) % 100` で `i` のマシンに持たせ、
受け付けたマシンがクエリ毎に該当するマシンに問い合わせる。

これは一定のマシンに極端な負荷がかかる可能性が考えられ、
キャッシュ処理とマシン間通信の効率がいくら良かったとしても、
筋が良いとは思えない。
また、各マシンが、
キャッシュはもちろん検索クエリ処理対象も含めて重複がないように持っていれば、
システム全体としては効率が良い面も出てくるが、
重複がある場合は効率が非常に悪い。

### コンテンツが変わった場合の結果更新

十分なキャッシュ・サイズを確保している場合、
よく参照されるキャッシュが恒久的に残る可能性がある。
これに対処する仕組みを考える。

以下にキャッシュの更新が必要になるケースを列挙する。

* URIのコンテンツが変わったとき。もしくはURIが除去された時。
* クエリに対する検索結果の順序が変わったとき。
* クエリに対する検索結果に新しいURIを追加するとき。

いずれのケースでも問題を解決できる方法としては、
キャッシュを定期的にチェックして、
あらかじめ決めておいた生存期間に従い、
参照頻度に関係なく古いデータを削除する処理が考えられる。

### さらなる機能改善

仮説が違えば、また、問題を少し変えれば、まだまだいろいろな方法が考えられる。

* キャッシュ処理も担当するフロントエンド・サーバを用意し、
  また、実際のクエリ処理担当のバックエンド・サーバを並列処理できるようにすることで、
  非常に高速な応答が実現できるようになる。
